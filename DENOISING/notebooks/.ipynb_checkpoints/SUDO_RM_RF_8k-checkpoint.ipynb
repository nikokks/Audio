{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from asteroid.metrics import get_metrics\n",
    "from pprint import pprint\n",
    "import asteroid\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.cuda.empty_cache()\n",
    "sys.path.append(\"sudo_rm_rf/\")\n",
    "\n",
    "# Get the pretrained models\n",
    "print(\"Pre-trained models available:\")\n",
    "for model_name in os.listdir('sudo_rm_rf/pretrained_models'):\n",
    "    print(model_name)\n",
    "    \n",
    "def normalize_tensor_wav(wav_tensor, eps=1e-8, std=None):\n",
    "    mean = wav_tensor.mean(-1, keepdim=True)\n",
    "    if std is None:\n",
    "        std = wav_tensor.std(-1, keepdim=True)\n",
    "    return (wav_tensor - mean) / (std + eps)\n",
    "    \n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt'\n",
    "noisy_reverberant_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt'\n",
    "noisy_reverberant_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt'\n",
    "\n",
    "# Load the appropriate class modules\n",
    "whamr_test_folder_path = 'data/8000'\n",
    "import sudo_rm_rf.dnn.experiments.utils.mixture_consistency as mixture_consistency\n",
    "import sudo_rm_rf.dnn.models.improved_sudormrf as improved_sudormrf\n",
    "import sudo_rm_rf.dnn.models.groupcomm_sudormrf_v2 as sudormrf_gc_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to understand the difference, play the output of a few different models\n",
    "all_anechoic_models_paths = [\n",
    "    'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt']\n",
    "\n",
    "\n",
    "\n",
    "FILES_PATH_INPUT = 'data_pipeline/8000_1/DPTNET/'\n",
    "FILES_INPUT = os.listdir(FILES_PATH_INPUT)\n",
    "for chosen_file in FILES_INPUT:\n",
    "    wav_path = chosen_file\n",
    "\n",
    "    anechoic_sampled_mixture, _ = torchaudio.load(FILES_PATH_INPUT+wav_path)\n",
    "\n",
    "    waveform = anechoic_sampled_mixture.detach().numpy()[0]\n",
    "\n",
    "\n",
    "    for anechoic_model_p in all_anechoic_models_paths:\n",
    "        name_folder = \"_\".join(anechoic_model_p.split('/')[-1].split('_')[2:4])\n",
    "        if not os.path.isdir('data_pipeline/8000_1/'+\"DPTNET_\"+name_folder):\n",
    "            os.mkdir('data_pipeline/8000_1/'+\"DPTNET_\"+name_folder)\n",
    "        model_name = os.path.basename(anechoic_model_p)\n",
    "        print(model_name)\n",
    "\n",
    "        # Load a pretrained model\n",
    "        anechoic_separation_model = torch.load(anechoic_model_p)\n",
    "\n",
    "        # Normalize the waveform and apply the model\n",
    "        input_mix_std = anechoic_sampled_mixture.std(-1, keepdim=True)\n",
    "        input_mix_mean = anechoic_sampled_mixture.mean(-1, keepdim=True)\n",
    "        input_mix = (anechoic_sampled_mixture - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "\n",
    "        # Apply the model\n",
    "        with torch.no_grad():\n",
    "            rec_sources_wavs = anechoic_separation_model(input_mix.unsqueeze(1))\n",
    "\n",
    "            # # In case you are using the pre-trained models with Group communication\n",
    "            # # please also use the mixture consistency right after the estimated waveforms\n",
    "            if \"GroupCom\" in model_name:\n",
    "                rec_sources_wavs = mixture_consistency.apply(rec_sources_wavs, input_mix.unsqueeze(1))\n",
    "\n",
    "            # Rescale the input sources with the mixture mean and variance\n",
    "            rec_sources_wavs = (rec_sources_wavs * input_mix_std) + input_mix_mean\n",
    "\n",
    "        torchaudio.save('data_pipeline/8000_1/'+'DPTNET_'+name_folder+\"/\"+chosen_file, normalize_tensor_wav(rec_sources_wavs[0]).detach(),8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
