{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained models available:\n",
      ".gitattributes\n",
      "download_pretrained_models.sh\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from asteroid.metrics import get_metrics\n",
    "from pprint import pprint\n",
    "import asteroid\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.cuda.empty_cache()\n",
    "sys.path.append(\"sudo_rm_rf/\")\n",
    "\n",
    "# Get the pretrained models\n",
    "print(\"Pre-trained models available:\")\n",
    "for model_name in os.listdir('sudo_rm_rf/pretrained_models'):\n",
    "    print(model_name)\n",
    "    \n",
    "def normalize_tensor_wav(wav_tensor, eps=1e-8, std=None):\n",
    "    mean = wav_tensor.mean(-1, keepdim=True)\n",
    "    if std is None:\n",
    "        std = wav_tensor.std(-1, keepdim=True)\n",
    "    return (wav_tensor - mean) / (std + eps)\n",
    "    \n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt'\n",
    "noisy_reverberant_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt'\n",
    "noisy_reverberant_model_p = 'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt'\n",
    "\n",
    "# Load the appropriate class modules\n",
    "whamr_test_folder_path = 'data/8000'\n",
    "import sudo_rm_rf.dnn.experiments.utils.mixture_consistency as mixture_consistency\n",
    "import sudo_rm_rf.dnn.models.improved_sudormrf as improved_sudormrf\n",
    "import sudo_rm_rf.dnn.models.groupcomm_sudormrf_v2 as sudormrf_gc_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395a81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1709551d5c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Load a pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0manechoic_separation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manechoic_model_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Normalize the waveform and apply the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testtt/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testtt/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testtt/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'"
     ]
    }
   ],
   "source": [
    "# Just to understand the difference, play the output of a few different models\n",
    "all_anechoic_models_paths = [\n",
    "    'sudo_rm_rf/pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt',\n",
    "    'sudo_rm_rf/pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt']\n",
    "\n",
    "\n",
    "\n",
    "FILES_PATH_INPUT = 'data_pipeline/8000_1/DPTNET/'\n",
    "FILES_INPUT = os.listdir(FILES_PATH_INPUT)\n",
    "for chosen_file in FILES_INPUT:\n",
    "    wav_path = chosen_file\n",
    "\n",
    "    anechoic_sampled_mixture, _ = torchaudio.load(FILES_PATH_INPUT+wav_path)\n",
    "\n",
    "    waveform = anechoic_sampled_mixture.detach().numpy()[0]\n",
    "\n",
    "\n",
    "    for anechoic_model_p in all_anechoic_models_paths:\n",
    "        name_folder = \"_\".join(anechoic_model_p.split('/')[-1].split('_')[2:4])\n",
    "        if not os.path.isdir('data_pipeline/8000_1/'+\"DPTNET_\"+name_folder):\n",
    "            os.mkdir('data_pipeline/8000_1/'+\"DPTNET_\"+name_folder)\n",
    "        model_name = os.path.basename(anechoic_model_p)\n",
    "        print(model_name)\n",
    "\n",
    "        # Load a pretrained model\n",
    "        anechoic_separation_model = torch.load(anechoic_model_p)\n",
    "\n",
    "        # Normalize the waveform and apply the model\n",
    "        input_mix_std = anechoic_sampled_mixture.std(-1, keepdim=True)\n",
    "        input_mix_mean = anechoic_sampled_mixture.mean(-1, keepdim=True)\n",
    "        input_mix = (anechoic_sampled_mixture - input_mix_mean) / (input_mix_std + 1e-9)\n",
    "\n",
    "        # Apply the model\n",
    "        with torch.no_grad():\n",
    "            rec_sources_wavs = anechoic_separation_model(input_mix.unsqueeze(1))\n",
    "\n",
    "            # # In case you are using the pre-trained models with Group communication\n",
    "            # # please also use the mixture consistency right after the estimated waveforms\n",
    "            if \"GroupCom\" in model_name:\n",
    "                rec_sources_wavs = mixture_consistency.apply(rec_sources_wavs, input_mix.unsqueeze(1))\n",
    "\n",
    "            # Rescale the input sources with the mixture mean and variance\n",
    "            rec_sources_wavs = (rec_sources_wavs * input_mix_std) + input_mix_mean\n",
    "\n",
    "        torchaudio.save('data_pipeline/8000_1/'+'DPTNET_'+name_folder+\"/\"+chosen_file, normalize_tensor_wav(rec_sources_wavs[0]).detach(),8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c65285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
