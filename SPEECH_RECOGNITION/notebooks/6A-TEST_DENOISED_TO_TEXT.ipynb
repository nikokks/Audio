{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5366a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b40dd55",
   "metadata": {},
   "source": [
    "# to load model offline\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"MODELS_SAVED/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"MODELS_SAVED/wav2vec2-large-960h-lv60-self\").eval()\n",
    "\n",
    "# to load model online\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48fd24c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eab0c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('/home/nikkokks/Desktop/Project_Alexa/Audio/SPEECH_RECOGNITION/notebooks/data_pipeline/16000_1/DTLN_DPTNET/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea616b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p226_002.wav\n",
      "['ASK HER TO BRING THESE THINGS WITH HER FROM THE STORE']\n",
      "p226_009.wav\n",
      "['THERE IS ACCORDING TO A LEGEND A BOILING POT OF GOLD AT ONE END']\n",
      "p226_007.wav\n",
      "['THE RAINBOW IS A DIVISION OF WHITE LIGHT INTO MANY BEAUTIFUL COLORS']\n",
      "p226_003.wav\n",
      "['SIX SPOONS OF FRESH SNOW PEAS FIVE THICK SLABS OF BLUE CHEESE AND MAYBE A SNACK FOR HER BROTHER BOB']\n",
      "p226_006.wav\n",
      "['WHEN THE SUNLIGHT STRIKES RAINDROPS IN THE AIR THEY ACT AS A PRISM AND FORM A RAINBOW']\n",
      "p226_001.wav\n",
      "['PLEASE CALL STELLA']\n",
      "p226_005.wav\n",
      "['SHE CAN SCOOP THESE THINGS INTO THREE RED BAGS AND WE WILL GO MEET HER WEDNESDAY AT THE TRAIN STATION']\n",
      "p226_004.wav\n",
      "['WE ALSO NEED A SMALL PLASTIC SNAKE AND A BIG TOY FROG FOR THE KIDS']\n",
      "p226_010.wav\n",
      "['PEOPLE LOOK BUT NO ONE EVER FINDS IT']\n",
      "p226_008.wav\n",
      "['THESE TAKE THE SHAPE OF A LONG ROUND ARCH WITH ITS PATH HIGH ABOVE AND ITS TWO ENDS APPARENTLY BEYOND THE HORIZON']\n"
     ]
    }
   ],
   "source": [
    "minimum = 9999999\n",
    "with torch.no_grad():\n",
    "    liste_denoised = []\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        ds = sf.read('/home/nikkokks/Desktop/Project_Alexa/Audio/SPEECH_RECOGNITION/notebooks/data_pipeline/16000_1/DTLN_DPTNET/'+file)\n",
    "        input_values = processor(ds[0], return_tensors=\"pt\", padding=\"longest\",num_process=6,sampling_rate=16000).input_values  # Batch size 1\n",
    "        output =  model(input_values)\n",
    "        output = torch.argmax(output.logits, dim=-1)\n",
    "        output = output.detach().to(device='cpu', dtype=torch.long)\n",
    "        transcription = processor.batch_decode(output)\n",
    "        print(transcription)\n",
    "        liste_denoised.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09685c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p226_002.wav\n",
      "['ASK HER TO BRING THESE THINGS WITH HER IN THE STORYT']\n",
      "p226_009.wav\n",
      "['THERE IS ACCORDING TO A LEGEND A BOILING POT OF GOLD AT ONE END']\n",
      "p226_007.wav\n",
      "['THE RAINBOW IS A DIVISION OF WHITE LIGHT INTO MANY BEAUTIFUL COLORS']\n",
      "p226_003.wav\n",
      "['B SIX SPOONS OF TH BREAKFAST NOW DONENTIL IT RRIVED FIVE SIX LABERLY AT MOCHEN NELL AND MAYBE A SNAPBOY HER BROTHER FOREO']\n",
      "p226_006.wav\n",
      "['WHEN THE SUNLIGHT STRIKES RAINDROPS IN THE AIR THEY ACT AS A PRISM AND FORM A RAINBERRY']\n",
      "p226_001.wav\n",
      "['PLEASE CALL STELLA']\n",
      "p226_005.wav\n",
      "['SHE CAN SCOOP THESE THINGS INTO THREE RED BAGS AND WE WILL GO MEET HER WEDNESDAY AT THE TRAIN STATION']\n",
      "p226_004.wav\n",
      "['O MI ONED NO A BUTTER A TRAL AND O BIGE TOY FROCAA  O']\n",
      "p226_010.wav\n",
      "['PEOPLE LOOK BUT NO ONE EVER FINDS IT']\n",
      "p226_008.wav\n",
      "['I SEEMED TO TAKE THE SHAPE OF A LONG ROUND ARCH WITH ITS PAT HIGH ABOVE AND ITS TWO ENDS APPARENTLY BEYOND THE HORIZON']\n"
     ]
    }
   ],
   "source": [
    "minimum = 9999999\n",
    "with torch.no_grad():\n",
    "    liste_denoised = []\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        ds = sf.read('/home/nikkokks/Desktop/Project_Alexa/Audio/SPEECH_RECOGNITION/notebooks/data_pipeline/16000_1/DTLN_DPTNET/'+file)\n",
    "        input_values = processor(ds[0], return_tensors=\"pt\", padding=\"longest\",num_process=6,sampling_rate=16000).input_values  # Batch size 1\n",
    "        output =  model(input_values)\n",
    "        output = torch.argmax(output.logits, dim=-1)\n",
    "        output = output.detach().to(device='cpu', dtype=torch.long)\n",
    "        transcription = processor.batch_decode(output)\n",
    "        print(transcription)\n",
    "        liste_denoised.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = 9999999\n",
    "with torch.no_grad():\n",
    "    liste_clean = []\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        ds = sf.read('clean_trainset_28spk_wav_FLAC/'+file)\n",
    "        input_values = processor(ds[0], return_tensors=\"pt\", padding=\"longest\",num_process=6,sampling_rate=16000).input_values  # Batch size 1\n",
    "        output =  model(input_values)\n",
    "        output = torch.argmax(output.logits, dim=-1)\n",
    "        output = output.detach().to(device='cpu', dtype=torch.long)\n",
    "        transcription = processor.batch_decode(output)\n",
    "        print(transcription)\n",
    "        liste_clean.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab75ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_word_error_rate(r, h):\n",
    "\n",
    "    \"\"\"\n",
    "    Given two list of strings how many word error rate(insert, delete or substitution).\n",
    "    \"\"\"\n",
    "    d = numpy.zeros((len(r) + 1) * (len(h) + 1), dtype=numpy.uint16)\n",
    "    d = d.reshape((len(r) + 1, len(h) + 1))\n",
    "    for i in range(len(r) + 1):\n",
    "        for j in range(len(h) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    for i in range(1, len(r) + 1):\n",
    "        for j in range(1, len(h) + 1):\n",
    "            if r[i - 1] == h[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    result = float(d[len(r)][len(h)]) / len(r) * 100\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_results = []\n",
    "for i in range(len(liste_clean)):\n",
    "    liste_results.append(get_word_error_rate(liste_denoised[i][0].split(),liste_clean[i][0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f403489",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(liste_results) # special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d54ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242866f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbb8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec89707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(liste_results) # wav2vec2 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(liste_results) # wav2vec2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b89b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550e3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
